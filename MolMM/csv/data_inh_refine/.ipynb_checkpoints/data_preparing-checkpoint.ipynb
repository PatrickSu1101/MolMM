{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51483472-c0cc-4333-9bbc-f1ec9f7fb4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from molmap import loadmap\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem.MolStandardize import rdMolStandardize\n",
    "from rdkit import RDLogger\n",
    "#IPythonConsole.ipython_useSVG = True\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from openbabel import pybel\n",
    "RDLogger.DisableLog('rdApp.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62476a64-412a-4dbb-ab8f-1fbc7793361a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp1 = loadmap('./test.mp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "add25173-59ae-4204-bf70-f7155b53340b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_standardize(smiles,ph=7.4,iso=False):\n",
    "    try:\n",
    "        # Convert SMILES to RDKit molecule\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        \n",
    "        # Skip invalid molecules\n",
    "        if mol is None:\n",
    "            return None,None\n",
    "\n",
    "        # Canonicalize the SMILES\n",
    "        # canonical_smiles = Chem.MolToSmiles(mol, isomericSmiles=True, canonical=True)\n",
    "\n",
    "        # Remove salts and other fragments / Keep only the largest fragment\n",
    "        fragments = Chem.GetMolFrags(mol, asMols=True)\n",
    "        largest_fragment = max(fragments, default=None, key=lambda m: m.GetNumAtoms())\n",
    "        if largest_fragment is None:\n",
    "            return None,None\n",
    "        \n",
    "        u = rdMolStandardize.Uncharger()\n",
    "        uncharge_mol = u.uncharge(largest_fragment)\n",
    "        uncharge_smiles = Chem.MolToSmiles(uncharge_mol, isomericSmiles=iso, canonical=True)\n",
    "        \n",
    "        ob_mol = pybel.readstring(\"smi\", Chem.MolToSmiles(largest_fragment, isomericSmiles=iso, canonical=True))\n",
    "        \n",
    "        ob_mol.OBMol.AddHydrogens(False, True, ph)\n",
    "\n",
    "        # Convert back to SMILES\n",
    "        adjusted_smiles = ob_mol.write(\"smi\").strip()\n",
    "\n",
    "        return adjusted_smiles, uncharge_smiles\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing SMILES {smiles}: {e}\")\n",
    "        return None,None\n",
    "    \n",
    "# def clean_csv(input_name,output_name):\n",
    "#     inh = pd.read_csv(input_name,encoding='utf-8')\n",
    "#     smiles_list = inh['smiles'].tolist()\n",
    "#     clean = []\n",
    "#     neu = []\n",
    "#     for smi in smiles_list:\n",
    "#         std_smi,neu_smi = clean_and_standardize(smi)\n",
    "#         clean.append(std_smi)\n",
    "#         neu.append(neu_smi)\n",
    "#     inh['clean_smiles_pH'] = clean\n",
    "#     inh['clean_smiles_neu'] = neu\n",
    "#     inh.to_csv(output_name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e60721d2-86f7-4317-9bd9-09fae390ae24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_csv(input_name,output_name):\n",
    "    inh = pd.read_csv(input_name,encoding='utf-8')\n",
    "    smiles_list = inh['smiles'].tolist()\n",
    "    clean = []\n",
    "    neu = []\n",
    "    for smi in smiles_list:\n",
    "        std_smi,neu_smi = clean_and_standardize(smi)\n",
    "        clean.append(std_smi)\n",
    "        neu.append(neu_smi)\n",
    "    inh['clean_smiles_pH'] = clean\n",
    "    inh['clean_smiles_neu'] = neu\n",
    "    inh.to_csv(output_name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c95ae064-5f26-463a-9b99-b0fdbb51c5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp1 = loadmap('./test.mp')\n",
    "def generate_MolDs(input_name,output_name,columns):\n",
    "    df = pd.read_csv(input_name, encoding='utf-8')\n",
    "    # smi = df['clean_smiles_pH']\n",
    "    smi = df[columns]\n",
    "    df_list = []\n",
    "    for s in tqdm(smi):\n",
    "        arr = mp1.extract.transform(s)\n",
    "        df = pd.DataFrame(arr).T\n",
    "        df.columns = mp1.extract.bitsinfo.IDs\n",
    "        df_list.append(df)\n",
    "    feat = pd.concat(df_list)\n",
    "    \n",
    "    rows_with_nan = np.array(feat.isna().any(axis=1),dtype=np.int_)\n",
    "    df = pd.read_csv(input_name,encoding='utf-8')\n",
    "    df[columns+'_valid'] = rows_with_nan\n",
    "    \n",
    "    mask0 = rows_with_nan == 0\n",
    "    feat = feat[mask0]\n",
    "    \n",
    "    df.to_csv(input_name,index=False)\n",
    "    feat.to_csv(output_name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5974f1d0-2d8d-4689-9a5f-caf345fffb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_map(input_name,output_name,columns):\n",
    "    df = pd.read_csv(input_name,encoding='utf-8')\n",
    "    mask = df[columns+'_valid']==0\n",
    "    smi = df[columns][mask].tolist()\n",
    "    F = mp1.batch_transform(smi)\n",
    "    np.savez(output_name,x=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11929879-c3e7-4768-a94e-6040fdfa3f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling_min_max(df):\n",
    "    df = mp1.MinMaxScaleClip(df,\n",
    "            mp1.scale_info['min'], \n",
    "            mp1.scale_info['max'])\n",
    "    df = df[mp1.flist]\n",
    "    return df\n",
    "\n",
    "def scaling_csv(name):\n",
    "    scaling_min_max(pd.read_csv(name)).to_csv('scaled_'+name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e27f93ff-ddba-49ac-a05b-6d5346959d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prepare(name,addition):\n",
    "    origin=name+'.csv'\n",
    "    clean='clean_'+name+'.csv'\n",
    "    if (name == addition):\n",
    "        clean_csv(origin,clean)\n",
    "        df = pd.read_csv(clean).drop_duplicates(subset='clean_smiles_pH')\n",
    "        df.to_csv(clean,index=False)\n",
    "        \n",
    "    clean_MolDs='clean_'+addition+'_MolDs.csv'\n",
    "    clean_npz = 'clean_'+addition+'.npz'\n",
    "    \n",
    "    if (name == addition):\n",
    "        generate_MolDs(clean,clean_MolDs,'clean_smiles_pH')\n",
    "        scaling_csv(clean_MolDs)\n",
    "        generate_map(clean,clean_npz,'clean_smiles_pH')\n",
    "    else:\n",
    "        generate_MolDs(clean,clean_MolDs,'clean_smiles_neu')\n",
    "        scaling_csv(clean_MolDs)\n",
    "        generate_map(clean,clean_npz,'clean_smiles_neu')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f47f82d4-6241-42ea-adb5-89c7dfd077ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 174/174 [00:28<00:00,  6.12it/s]\n",
      "100%|##########| 174/174 [00:07<00:00, 24.21it/s]\n",
      "100%|██████████| 174/174 [00:28<00:00,  6.08it/s]\n",
      "100%|##########| 174/174 [00:07<00:00, 24.06it/s]\n"
     ]
    }
   ],
   "source": [
    "for name in ['refine_inhibitors']:\n",
    "    data_prepare(name,name)\n",
    "    data_prepare(name,name+'_neu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdbdb0f-ce6b-4278-bceb-0a847d0a1d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 21/130 [00:03<00:16,  6.42it/s]"
     ]
    }
   ],
   "source": [
    "for name in ['refine_substrates']:\n",
    "    data_prepare(name,name)\n",
    "    data_prepare(name,name+'_neu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab187954-716d-4386-82ac-58eb7cd37dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8181c32a-aab0-4943-ae7c-14f841f06891",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_refine_inhibitors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b245191-c357-4e0b-bed6-4cd0abd2ddfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 115)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['labels'].sum(), len(df)-df['labels'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84d10e1e-9167-4846-b1ab-f97ce889fd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_refine_substrates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "420b8586-d3a0-4731-ab6d-a222fd3d66ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193, 191)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['labels'].sum(), len(df)-df['labels'].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molmap",
   "language": "python",
   "name": "molmap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
